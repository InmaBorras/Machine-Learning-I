{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Random Forest y Decision Tree\n",
    "\n",
    "Realizamos los modelos de Random Forest y Decision Tree y su posterior ajuste de hiperpámetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "#seleccion de variables ver si merece la pena meterlo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import pandas as pd \n",
    "\n",
    "#modelado del machine learning esto meter si o si\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "#para hacer el PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "#PARA HACER EL GRADIENTE DEL ERROR\n",
    "\n",
    "#Decision Tree Regression with AdaBoost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos funciones que creen  modelos con diferentes rangos que cambian  el valor del parametro que queremos ajustar para hayar el valor del hiperparámetro optimo. \n",
    "\n",
    " Lo realizamos sobre  Random Forest y Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tune_sklearn import TuneGridSearchCV\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "# explore number of features from 1 to 7\n",
    "    for i in range(1,6):\n",
    "\t    models[str(i)] = RandomForestClassifier(max_features=i)\n",
    "    return models\n",
    "def get_models_estimator():\n",
    "    models = dict()\n",
    "\t# define number of trees to consider\n",
    "    n_trees = [10, 50, 100, 500, 1000]\n",
    "    for n in n_trees:\n",
    "    \tmodels[str(n)] = RandomForestClassifier(n_estimators=n)\n",
    "    return models\n",
    "\n",
    "def get_models_depth():\n",
    "    models = dict()\n",
    "\t# consider tree depths from 1 to 7 and None=full\n",
    "    depths = [i for i in range(1,20)] + [None]\n",
    "    for n in depths:\n",
    "    \tmodels[str(n)] = RandomForestClassifier(max_depth=n)\n",
    "    return models\n",
    "\n",
    "\n",
    "def get_models_DT():\n",
    "    models = dict()\n",
    "# explore number of features from 1 to 7\n",
    "    for i in range(1,15):\n",
    "\t    models[str(i)] = DecisionTreeClassifier(max_features=i)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_depth_DT():\n",
    "    models = dict()\n",
    "\t# consider tree depths from 1 to 7 and None=full\n",
    "    depths = [i for i in range(1,20)] + [None]\n",
    "    for n in depths:\n",
    "    \tmodels[str(n)] = DecisionTreeClassifier(max_depth=n)\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " En la función evaluar_hiperparametros_modelo, aplicamos las funciones anteriores y optenemos una lista de modelos sobre los cuales aplicamos la validacion crizada con diferentes valores para  un único hiperpárametro. \n",
    "\n",
    "De la cual optenemos un box plot de cada modelo en función a los resultados obtenido de los resultados de la validación cruzada. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "def evaluar_hiperparametros_modelo(models,X,y):\n",
    "    results, names = list(), list()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        # store the results\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        # summarize the performance along the way\n",
    "        print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    # plot model performance for comparison\n",
    "    pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=pd.read_csv('./CSV/csv_precio_div.csv')\n",
    "\n",
    "\n",
    "features=['Rooms','Distance','Bathroom','Landsize','Lattitude','Longtitude']\n",
    "X=datos[features] \n",
    "y=datos['precio_div']\n",
    "\n",
    "scoring = {'accuracy':make_scorer(accuracy_score), \n",
    "           'precision':make_scorer(precision_score),\n",
    "           'recall':make_scorer(recall_score), \n",
    "           'f1_score':make_scorer(f1_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Ajuste de hiperparámetros  de Random Fores y Decision Tree.\n",
    "\n",
    "Imprimimos por pantalla los resultados de los box plot de cada uno de los hiperparametros y obtenemos cual es el que ajusta el modelo con un mejor resultado. \n",
    "\n",
    "Elegimos los mejores hiperparámetros para estos dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.955 (0.005)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = get_models()\n",
    "evaluar_hiperparametros_modelo(models,X,y)\n",
    "\n",
    "models = get_models_DT()\n",
    "evaluar_hiperparametros_modelo(models,X,y)\n",
    "  \n",
    "\n",
    "models =get_models_estimator()\n",
    "evaluar_hiperparametros_modelo(models,X,y)\n",
    "\n",
    "\n",
    "models =get_models_depth()\n",
    "evaluar_hiperparametros_modelo(models,X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos los hiperparámetros también atraves de GrindseachCSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otro tipo de cálculo de hiperparámetros a partir de gridsearchcvf\n",
    "param_grid= {'criterion': ['gini', 'entropy'],'max_depth': [None, 1 , 3, 5, 10],'min_samples_split': [5,10],'min_samples_leaf':[5,10]}\n",
    "\n",
    "gs_rf=GridSearchCV(RandomForestClassifier(),param_grid=param_grid)\n",
    "gs_rf.fit(X_train,y_train)\n",
    "y_pred=gs_rf.predict(X)\n",
    "\n",
    "param_grid= {'criterion': ['gini', 'entropy'],'max_depth': [None, 3 , 5, 10, 20],'min_samples_split': [5,10],'min_samples_leaf':[5,10]}\n",
    "\n",
    "gs_rf=GridSearchCV(DecisionTreeClassifier(),param_grid=param_grid)\n",
    "gs_rf.fit(X_train,y_train)\n",
    "y_pred=gs_rf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la combinación de ambas formas de ajuste de hiperparámetros usaremos para la la evaluación del modelo y seleccionar el mejor. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}